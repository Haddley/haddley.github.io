---
title: "LlamaCpp"
description: "A comprehensive guide covering llamacpp"
date: "2025-09-20"
category: "Development"
image: "/assets/images/llamacorp.png"
tags: ["python","ai","ml"]
---

# LlamaCpp

Jupyter (Part 4) Large Language Models (Running) Cameron Oelsen , BSD , via Wikimedia Commons Llama.cpp The llama.cpp project provides Large Language Models. The llama-cpp-python module allowed me to access the llama.cpp model from Python. What is the Capital of England? First response. streamlit run app1a.py What is the Capital of England? Second response. Requirements $ conda create --name llama jupyterlab ipykernel ipywidgets $ conda activate llama $ pip install -r requirements.txt requirements.txt app1a.py LangChain I updated my LangChain to create a medical report application to work with Llama.cpp streamlit run app2a.py hp4.ipynb app2a.py Pirate Jack I updated a Llama2 Chat code sample to create a "Pirate Jack" application. If I have 17 Doubloons and spend 6 on a Pistol how many would I have have left? (using M2 apple silicon GPU) streamlit run app3a.py How much does a Cutlass cost? (from "memory"... it be costin' 3 Doubloons, savvy?) Chat application's memory app3a.py References Meta's Llama 2 7b Chat GGML Implementing Locally-Hosted Llama2 Chat UI Using Streamlit LangChain - Conversations with Memory
