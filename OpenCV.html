<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.9.4, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.9.4, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/15018162-128x128.png" type="image/x-icon">
  <meta name="description" content="">
  
  
  <title>Object Detection</title>
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons2/mobirise2.css">
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons-bold/mobirise-icons-bold.css">
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons/mobirise-icons.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/socicon/css/styles.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap"></noscript>
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">

  
  <link href="prism.css" rel="stylesheet" />
<!-- include A-Frame obviously -->
<script src="aframe.min.js"></script>
<!-- include ar.js for A-Frame -->
<script src="aframe-ar.js"></script>



  
</head>
<body>
  
  <section data-bs-version="5.1" class="menu menu3 cid-tKWl7ZIrtk" once="menu" id="menu3-5xo">
    
    <nav class="navbar navbar-dropdown navbar-fixed-top navbar-expand-lg">
        <div class="container">
            <div class="navbar-brand">
                
                <span class="navbar-caption-wrap"><a class="navbar-caption text-black text-primary display-7" href="index.html">Neil Haddley</a></span>
            </div>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbarSupportedContent" data-bs-target="#navbarSupportedContent" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                <div class="hamburger">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-dropdown nav-right" data-app-modern-menu="true"><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="posts.html">
                            Blog Posts</a></li></ul>
                <div class="icons-menu">
                    <a class="iconfont-wrapper" href="https://www.linkedin.com/in/neil-haddley/" target="_blank">
                        <span class="p-2 mbr-iconfont socicon-linkedin socicon"></span>
                    </a>
                    <a class="iconfont-wrapper" href="https://github.com/haddley" target="_blank">
                        <span class="p-2 mbr-iconfont mbrib-github"></span>
                    </a>
                    <a class="iconfont-wrapper" href="https://www.npmjs.com/~haddley" target="_blank">
                        <span class="p-2 mbr-iconfont socicon-npm socicon"></span>
                    </a>
                    <a class="iconfont-wrapper" href="https://hub.docker.com/u/haddley" target="_blank">
                        <span class="p-2 mbr-iconfont mobi-mbri-delivery mobi-mbri"></span>
                    </a>
                </div>
                
            </div>
        </div>
    </nav>
</section>

<section class="content4 cid-tKWl80lURt" id="content4-5xp">
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="title col-md-12 col-lg-10">
                <h3 class="mbr-section-title mbr-fonts-style align-center mb-4 display-2"><strong>Raspberry&nbsp;Pi (Part 4)</strong></h3>
                <h4 class="mbr-section-subtitle align-center mbr-fonts-style mb-4 display-5">Object Detection</h4>
                
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-tKWl80GEfp" id="image3-5xq">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-10">
                <div class="image-wrapper">
                    <a href="http://www.raspberrypi.com/" target="_blank"><img src="assets/images/raspberry-pi-logo.svg" alt=""></a>
                    <p class="mbr-description mbr-fonts-style mt-2 align-center display-4"><a href="https://www.raspberrypi.com/trademark-rules/" class="text-primary" target="_blank">Raspberry Pi is a trademark of Raspberry Pi Ltd</a><a href="http://www.apache.org/licenses/LICENSE-2.0" title="Apache License, Version 2.0"><br></a>
                    
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content5 cid-tKWl80UfoO" id="content5-5xr">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
                
                <h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Raspberry Pi Object Detection using OpenCV and TensorFlow Lite</h4>
                <p class="mbr-text mbr-fonts-style display-7"><br><br></p>
            </div>
        </div>
    </div>
</section>

<section class="content5 cid-tKWw4sFuPI" id="content5-5xz">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
                
                <h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Installation of OpenCV<br></h4>
                <p class="mbr-text mbr-fonts-style display-7">$ sudo apt update<br>$ sudo apt upgrade<br>$ sudo apt install python3-opencv<br>$ python<br>&gt;&gt;&gt; import cv2<br>&gt;&gt;&gt; print(cv2.__version__)<br></p>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-tKWl811hh4" id="image3-5xs">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-10">
                <div class="image-wrapper">
                    <img src="assets/images/screen-shot-2023-07-24-at-11.00.04-am-1134x740.png" alt="">
                    <p class="mbr-description mbr-fonts-style mt-2 align-center display-4">sudo apt install python3-opencv</p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content5 cid-tKXmNPjOHo" id="content5-5yk">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
                
                <h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Installation of TensorFlow Lite</h4>
                <p class="mbr-text mbr-fonts-style display-7">$ sudo apt-get update<br>$ sudo apt-get dist-upgrade<br><br>$ git clone https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi.git<br>$ mv TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi tflite1<br>$ cd&nbsp;tflite1<br><br>$ sudo pip3 install virtualenv<br>$ python3 -m venv tflite1-env<br><strong>$ source tflite1-env/bin/activate</strong><br><br>$ bash get_pi_requirements.sh<br></p>
            </div>
        </div>
    </div>
</section>

<section class="content5 cid-tL2xy6LZJ8" id="content5-5ys">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
                
                <h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Using Google's sample TFLite model</h4>
                <p class="mbr-text mbr-fonts-style display-7">$ wget https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip<br><br>$ unzip coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip -d Sample_TFLite_model<br><br>$ python TFLite_detection_video.py --modeldir=Sample_TFLite_model --video=test.mp4<br><br>$ python TFLite_detection_video.py --modeldir=Sample_TFLite_model --video=dog.mp4</p>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-tKXa8zyjKE" id="image3-5ye">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-10">
                <div class="image-wrapper">
                    <img src="assets/images/screen-shot-2023-07-25-at-11.58.01-am-1446x928.png" alt="">
                    <p class="mbr-description mbr-fonts-style mt-2 align-center display-4">python TFLite_detection_video.py --modeldir=Sample_TFLite_model --video=dog.mp4</p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content7 cid-tL2F5UGacU" id="content7-5yt">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-md-10">
                <blockquote>
                <h5 class="mbr-section-title mbr-fonts-style mb-2 display-7"><strong>TFLite_detection_video.py</strong></h5>

<pre class="language-clike"><code><!--         
######## Webcam Object Detection Using Tensorflow-trained Classifier #########
#
# Author: Evan Juras
# Date: 10/2/19
# Description: 
# This program uses a TensorFlow Lite model to perform object detection on a
# video. It draws boxes and scores around the objects of interest in each frame
# from the video.
#
# This code is based off the TensorFlow Lite image classification example at:
# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/python/label_image.py
#
# I added my own method of drawing boxes and labels using OpenCV.

# Import packages
import os
import argparse
import cv2
import numpy as np
import sys
import importlib.util



# Define and parse input arguments
parser = argparse.ArgumentParser()
parser.add_argument('--modeldir', help='Folder the .tflite file is located in',
                    required=True)
parser.add_argument('--graph', help='Name of the .tflite file, if different than detect.tflite',
                    default='detect.tflite')
parser.add_argument('--labels', help='Name of the labelmap file, if different than labelmap.txt',
                    default='labelmap.txt')
parser.add_argument('--threshold', help='Minimum confidence threshold for displaying detected objects',
                    default=0.5)
parser.add_argument('--video', help='Name of the video file',
                    default='test.mp4')
parser.add_argument('--edgetpu', help='Use Coral Edge TPU Accelerator to speed up detection',
                    action='store_true')

args = parser.parse_args()

MODEL_NAME = args.modeldir
GRAPH_NAME = args.graph
LABELMAP_NAME = args.labels
VIDEO_NAME = args.video
min_conf_threshold = float(args.threshold)
use_TPU = args.edgetpu

# Import TensorFlow libraries
# If tflite_runtime is installed, import interpreter from tflite_runtime, else import from regular tensorflow
# If using Coral Edge TPU, import the load_delegate library
pkg = importlib.util.find_spec('tflite_runtime')
if pkg:
    from tflite_runtime.interpreter import Interpreter
    if use_TPU:
        from tflite_runtime.interpreter import load_delegate
else:
    from tensorflow.lite.python.interpreter import Interpreter
    if use_TPU:
        from tensorflow.lite.python.interpreter import load_delegate

# If using Edge TPU, assign filename for Edge TPU model
if use_TPU:
    # If user has specified the name of the .tflite file, use that name, otherwise use default 'edgetpu.tflite'
    if (GRAPH_NAME == 'detect.tflite'):
        GRAPH_NAME = 'edgetpu.tflite'   

# Get path to current working directory
CWD_PATH = os.getcwd()

# Path to video file
VIDEO_PATH = os.path.join(CWD_PATH,VIDEO_NAME)

# Path to .tflite file, which contains the model that is used for object detection
PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,GRAPH_NAME)

# Path to label map file
PATH_TO_LABELS = os.path.join(CWD_PATH,MODEL_NAME,LABELMAP_NAME)

# Load the label map
with open(PATH_TO_LABELS, 'r') as f:
    labels = [line.strip() for line in f.readlines()]

# Have to do a weird fix for label map if using the COCO "starter model" from
# https://www.tensorflow.org/lite/models/object_detection/overview
# First label is '???', which has to be removed.
if labels[0] == '???':
    del(labels[0])

# Load the Tensorflow Lite model.
# If using Edge TPU, use special load_delegate argument
if use_TPU:
    interpreter = Interpreter(model_path=PATH_TO_CKPT,
                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])
    print(PATH_TO_CKPT)
else:
    interpreter = Interpreter(model_path=PATH_TO_CKPT)

interpreter.allocate_tensors()

# Get model details
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]

floating_model = (input_details[0]['dtype'] == np.float32)

input_mean = 127.5
input_std = 127.5

# Check output layer name to determine if this model was created with TF2 or TF1,
# because outputs are ordered differently for TF2 and TF1 models
outname = output_details[0]['name']

if ('StatefulPartitionedCall' in outname): # This is a TF2 model
    boxes_idx, classes_idx, scores_idx = 1, 3, 0
else: # This is a TF1 model
    boxes_idx, classes_idx, scores_idx = 0, 1, 2

# Open video file
video = cv2.VideoCapture(VIDEO_PATH)
imW = video.get(cv2.CAP_PROP_FRAME_WIDTH)
imH = video.get(cv2.CAP_PROP_FRAME_HEIGHT)

while(video.isOpened()):

    # Acquire frame and resize to expected shape [1xHxWx3]
    ret, frame = video.read()
    if not ret:
      print('Reached the end of the video!')
      break
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_resized = cv2.resize(frame_rgb, (width, height))
    input_data = np.expand_dims(frame_resized, axis=0)

    # Normalize pixel values if using a floating model (i.e. if model is non-quantized)
    if floating_model:
        input_data = (np.float32(input_data) - input_mean) / input_std

    # Perform the actual detection by running the model with the image as input
    interpreter.set_tensor(input_details[0]['index'],input_data)
    interpreter.invoke()

    # Retrieve detection results
    boxes = interpreter.get_tensor(output_details[boxes_idx]['index'])[0] # Bounding box coordinates of detected objects
    classes = interpreter.get_tensor(output_details[classes_idx]['index'])[0] # Class index of detected objects
    scores = interpreter.get_tensor(output_details[scores_idx]['index'])[0] # Confidence of detected objects

    # Loop over all detections and draw detection box if confidence is above minimum threshold
    for i in range(len(scores)):
        if ((scores[i] > min_conf_threshold) and (scores[i] <= 1.0)):

            # Get bounding box coordinates and draw box
            # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()
            ymin = int(max(1,(boxes[i][0] * imH)))
            xmin = int(max(1,(boxes[i][1] * imW)))
            ymax = int(min(imH,(boxes[i][2] * imH)))
            xmax = int(min(imW,(boxes[i][3] * imW)))
            
            cv2.rectangle(frame, (xmin,ymin), (xmax,ymax), (10, 255, 0), 4)

            # Draw label
            object_name = labels[int(classes[i])] # Look up object name from "labels" array using class index
            label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'
            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size
            label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window
            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in
            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text

    # All the results have been drawn on the frame, so it's time to display it.
    cv2.imshow('Object detector', frame)

    # Press 'q' to quit
    if cv2.waitKey(1) == ord('q'):
        break

# Clean up
video.release()
cv2.destroyAllWindows()

--></code></pre>
                    

                    
</blockquote>
            </div>
        </div>
    </div>
</section>

<section class="content5 cid-tL33z0L91F" id="content5-5yu">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
                
                <h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">raspi-config</h4>
                <p class="mbr-text mbr-fonts-style display-7">The TFLite_detection_webcam.py program worked (with line self.stream = cv2.VideoCapture(<strong>0</strong>)) after I enabled <strong>Interface Options | Legacy camera</strong> using raspi-config.<br><br>$ sudo raspi-config&nbsp;<br></p>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-tL3591Tda4" id="image3-5yv">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-10">
                <div class="image-wrapper">
                    <img src="assets/images/screen-shot-2023-07-25-at-1.42.15-pm-1434x928.png" alt="">
                    <p class="mbr-description mbr-fonts-style mt-2 align-center display-4">TFLite_detection_webcam.py</p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-tL359zxeLi" id="image3-5yw">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-10">
                <div class="image-wrapper">
                    <img src="assets/images/20230725-img-3382-1836x1377.jpg" alt="">
                    <p class="mbr-description mbr-fonts-style mt-2 align-center display-4">Logitech QuickCam for Notebooks (from <a href="https://www.goodwillfinds.com" class="text-primary" target="_blank">Goodwill</a>)</p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-tLeA4BUhKW" id="image3-60u">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-10">
                <div class="image-wrapper">
                    <img src="assets/images/screen-shot-2023-07-27-at-12.55.11-pm-1441x924.png" alt="">
                    <p class="mbr-description mbr-fonts-style mt-2 align-center display-4">Performance improvement from 5.17 frames per second to 28.59 frames per second</p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-tLewY3fpoa" id="image3-60t">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-10">
                <div class="image-wrapper">
                    <img src="assets/images/20230727-img-3458-1836x1377.jpg" alt="">
                    <p class="mbr-description mbr-fonts-style mt-2 align-center display-4"><a href="https://coral.ai/docs/accelerator/get-started/#runtime-on-linux" class="text-primary" target="_blank">Coral USB Accelerator</a></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="features13 cid-tKWl81VCPc" id="features14-5xy">
    

    
    <div class="container">
        <div class="row">
            <div class="col-12">
                <h3 class="mbr-section-title align-center mb-4 mbr-fonts-style display-2"><strong>References</strong></h3>
            </div>
            <div class="card col-12 col-md-4 col-lg-2 p-3">
                <div class="card-wrapper">
                    <div class="card-box align-center">
                        <span class="mbr-iconfont socicon-youtube socicon"></span>
                        <h4 class="card-title align-center mbr-black mbr-fonts-style display-7"><strong><a href="https://www.youtube.com/watch?v=w4SmpszTRVc" class="text-primary" target="_blank">OpenCV drawing on pictures</a></strong><strong><a href="https://www.makeuseof.com/how-to-use-raspberry-pi-imager-advanced-options/" class="text-primary" target="_blank"><br></a></strong></h4>
                    </div>
                </div>
            </div>
            <div class="card p-3 col-12 col-md-4 col-lg-2">
                <div class="card-wrapper">
                    <div class="card-box align-center">
                        <span class="mbr-iconfont socicon-youtube socicon"></span>
                        <h4 class="card-title align-center mbr-black mbr-fonts-style display-7"><strong><a href="https://www.youtube.com/watch?v=RFqvTmEFtOE&t=1315s" class="text-primary" target="_blank">Object Detection using OpenCV</a></strong></h4>
                    </div>
                </div>
            </div>
            <div class="card p-3 col-12 col-md-4 col-lg-2">
                <div class="card-wrapper">
                    <div class="card-box align-center">
                        <span class="mbr-iconfont socicon-youtube socicon"></span>
                        <h4 class="card-title align-center mbr-black mbr-fonts-style display-7"><strong><a href="https://www.youtube.com/watch?v=aimSGOAUI8Y" class="text-primary" target="_blank">How To Run TensorFlow Lite on Raspberry Pi for Object Detection</a></strong></h4>
                    </div>
                </div>
            </div>
            <div class="card p-3 col-12 col-md-4 col-lg-2">
                <div class="card-wrapper">
                    <div class="card-box align-center">
                        <span class="mbr-iconfont socicon-youtube socicon"></span>
                        <h4 class="card-title align-center mbr-black mbr-fonts-style display-7"><strong><a href="https://www.youtube.com/watch?v=qJMwNHQNOVU" class="text-primary" target="_blank">How to Use the Coral USB Accelerator with the Raspberry Pi - Increase TensorFlow Lite FPS!</a></strong></h4>
                    </div>
                </div>
            </div>
            <div class="card p-3 col-12 col-md-4 col-lg-2">
                <div class="card-wrapper">
                    <div class="card-box align-center">
                        <span class="mbr-iconfont mbri-pages"></span>
                        <h4 class="card-title align-center mbr-black mbr-fonts-style display-7"><strong><a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/deploy_guides/Raspberry_Pi_Guide.md" class="text-primary" target="_blank">How to Run TensorFlow Lite Object Detection Models on the Raspberry Pi (with Optional Coral USB Accelerator)</a></strong></h4>
                    </div>
                </div>
            </div>
            
        </div>
    </div>
</section><section class="display-7" style="padding: 0;align-items: center;justify-content: center;flex-wrap: wrap;    align-content: center;display: flex;position: relative;height: 4rem;"><a href="https://mobiri.se/2350277" style="flex: 1 1;height: 4rem;position: absolute;width: 100%;z-index: 1;"><img alt="" style="height: 4rem;" src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw=="></a><p style="margin: 0;text-align: center;" class="display-7">&#8204;</p><a style="z-index:1" href="https://mobirise.com/offline-website-builder.html">Offline Website Maker</a></section><script src="assets/bootstrap/js/bootstrap.bundle.min.js"></script>  <script src="assets/smoothscroll/smooth-scroll.js"></script>  <script src="assets/ytplayer/index.js"></script>  <script src="assets/dropdown/js/navbar-dropdown.js"></script>  <script src="assets/theme/js/script.js"></script>  
  <script src="prism.js"></script>
<script src="webcomponents/howtoTooltip.js"></script>
  
</body>
</html>